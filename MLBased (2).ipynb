{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6egRcK2dlE1Z"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnaV8x2KoNBU"
      },
      "outputs": [],
      "source": [
        "def fetch_data(tickers, start='2009-05-01', end='2025-01-01'):\n",
        "    data_dict = {}\n",
        "    for ticker in tickers:\n",
        "        print(f\"Fetching {ticker}...\")\n",
        "        df = yf.download(ticker, start=start, end=end)\n",
        "        df.dropna(inplace=True)\n",
        "        df['SMA50'] = df['Close'].rolling(window=50).mean()\n",
        "        df['SMA200'] = df['Close'].rolling(window=200).mean()\n",
        "        data_dict[ticker] = df\n",
        "    return data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3uMcplDoQiV",
        "outputId": "57023d20-ee5d-4bb3-e016-7a6c89e684e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching AAPL...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2-3062552244.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(ticker, start=start, end=end)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-2-3062552244.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(ticker, start=start, end=end)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching JPM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-2-3062552244.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(ticker, start=start, end=end)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching XOM...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "data_dict = fetch_data(['AAPL', 'JPM', 'XOM'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTbURR7HoVCd"
      },
      "outputs": [],
      "source": [
        "def add_indicators(df, ticker):\n",
        "  # RSI\n",
        "  delta = df[f'Close_{ticker}'].diff()\n",
        "  gain = delta.clip(lower=0)\n",
        "  loss = -delta.clip(upper=0)\n",
        "  avg_gain = gain.rolling(window=14).mean()\n",
        "  avg_loss = loss.rolling(window=14).mean()\n",
        "  rs = avg_gain / avg_loss\n",
        "  df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "  # Bollinger Bands\n",
        "  rolling_mean = df[f'Close_{ticker}'].rolling(window=20).mean()\n",
        "  rolling_std = df[f'Close_{ticker}'].rolling(window=20).std()\n",
        "  df['Bollinger_Upper'] = rolling_mean + (rolling_std * 2)\n",
        "  df['Bollinger_Lower'] = rolling_mean - (rolling_std * 2)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMac_L9Boc69"
      },
      "outputs": [],
      "source": [
        "# Flattening the column names\n",
        "\n",
        "for ticker, df in data_dict.items():\n",
        "    df.columns = [col[0] if col[1] == '' else f\"{col[0]}_{col[1]}\" for col in df.columns]\n",
        "    data_dict[ticker] = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "tFk0MZLhod0U",
        "outputId": "c49911ba-2b81-4ab2-fc7b-74ce4cfaa97e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Close_XOM    High_XOM     Low_XOM    Open_XOM  Volume_XOM  \\\n",
              "Date                                                                     \n",
              "2009-05-01   37.262051   37.289443   36.204621   36.779904    27385000   \n",
              "2009-05-04   37.366161   37.755168   37.075780   37.530530    27306100   \n",
              "2009-05-05   37.064804   37.431890   36.796339   37.300397    19910300   \n",
              "2009-05-06   37.574360   37.585316   36.949765   37.278498    30814800   \n",
              "2009-05-07   37.766117   37.826385   37.048381   37.804469    32541600   \n",
              "...                ...         ...         ...         ...         ...   \n",
              "2024-12-24  104.494308  105.270160  103.806841  104.612154     7807000   \n",
              "2024-12-26  104.582695  105.113024  104.042550  104.612156     9652400   \n",
              "2024-12-27  104.572876  106.055825  103.875586  104.396100    11943900   \n",
              "2024-12-30  103.865776  104.651443  103.620254  104.396105    11080800   \n",
              "2024-12-31  105.643356  105.967448  103.885415  104.268430    12387800   \n",
              "\n",
              "                 SMA50      SMA200  \n",
              "Date                                \n",
              "2009-05-01         NaN         NaN  \n",
              "2009-05-04         NaN         NaN  \n",
              "2009-05-05         NaN         NaN  \n",
              "2009-05-06         NaN         NaN  \n",
              "2009-05-07         NaN         NaN  \n",
              "...                ...         ...  \n",
              "2024-12-24  114.108599  112.693227  \n",
              "2024-12-26  113.855630  112.697006  \n",
              "2024-12-27  113.596425  112.694937  \n",
              "2024-12-30  113.329117  112.680034  \n",
              "2024-12-31  113.103985  112.674979  \n",
              "\n",
              "[3944 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07075613-93e0-413d-b950-65dfdb32dd84\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close_XOM</th>\n",
              "      <th>High_XOM</th>\n",
              "      <th>Low_XOM</th>\n",
              "      <th>Open_XOM</th>\n",
              "      <th>Volume_XOM</th>\n",
              "      <th>SMA50</th>\n",
              "      <th>SMA200</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2009-05-01</th>\n",
              "      <td>37.262051</td>\n",
              "      <td>37.289443</td>\n",
              "      <td>36.204621</td>\n",
              "      <td>36.779904</td>\n",
              "      <td>27385000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-05-04</th>\n",
              "      <td>37.366161</td>\n",
              "      <td>37.755168</td>\n",
              "      <td>37.075780</td>\n",
              "      <td>37.530530</td>\n",
              "      <td>27306100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-05-05</th>\n",
              "      <td>37.064804</td>\n",
              "      <td>37.431890</td>\n",
              "      <td>36.796339</td>\n",
              "      <td>37.300397</td>\n",
              "      <td>19910300</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-05-06</th>\n",
              "      <td>37.574360</td>\n",
              "      <td>37.585316</td>\n",
              "      <td>36.949765</td>\n",
              "      <td>37.278498</td>\n",
              "      <td>30814800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-05-07</th>\n",
              "      <td>37.766117</td>\n",
              "      <td>37.826385</td>\n",
              "      <td>37.048381</td>\n",
              "      <td>37.804469</td>\n",
              "      <td>32541600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-24</th>\n",
              "      <td>104.494308</td>\n",
              "      <td>105.270160</td>\n",
              "      <td>103.806841</td>\n",
              "      <td>104.612154</td>\n",
              "      <td>7807000</td>\n",
              "      <td>114.108599</td>\n",
              "      <td>112.693227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-26</th>\n",
              "      <td>104.582695</td>\n",
              "      <td>105.113024</td>\n",
              "      <td>104.042550</td>\n",
              "      <td>104.612156</td>\n",
              "      <td>9652400</td>\n",
              "      <td>113.855630</td>\n",
              "      <td>112.697006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-27</th>\n",
              "      <td>104.572876</td>\n",
              "      <td>106.055825</td>\n",
              "      <td>103.875586</td>\n",
              "      <td>104.396100</td>\n",
              "      <td>11943900</td>\n",
              "      <td>113.596425</td>\n",
              "      <td>112.694937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-30</th>\n",
              "      <td>103.865776</td>\n",
              "      <td>104.651443</td>\n",
              "      <td>103.620254</td>\n",
              "      <td>104.396105</td>\n",
              "      <td>11080800</td>\n",
              "      <td>113.329117</td>\n",
              "      <td>112.680034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-12-31</th>\n",
              "      <td>105.643356</td>\n",
              "      <td>105.967448</td>\n",
              "      <td>103.885415</td>\n",
              "      <td>104.268430</td>\n",
              "      <td>12387800</td>\n",
              "      <td>113.103985</td>\n",
              "      <td>112.674979</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3944 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07075613-93e0-413d-b950-65dfdb32dd84')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07075613-93e0-413d-b950-65dfdb32dd84 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07075613-93e0-413d-b950-65dfdb32dd84');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-603a4d41-1d3c-4558-ac04-3cdab92471c7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-603a4d41-1d3c-4558-ac04-3cdab92471c7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-603a4d41-1d3c-4558-ac04-3cdab92471c7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c5d62e02-38ce-495d-acb3-5049c23f0ef7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c5d62e02-38ce-495d-acb3-5049c23f0ef7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3944,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2009-05-01 00:00:00\",\n        \"max\": \"2024-12-31 00:00:00\",\n        \"num_unique_values\": 3944,\n        \"samples\": [\n          \"2024-01-31 00:00:00\",\n          \"2020-11-19 00:00:00\",\n          \"2016-10-05 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close_XOM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.059913753465842,\n        \"min\": 24.582963943481445,\n        \"max\": 122.12105560302734,\n        \"num_unique_values\": 3789,\n        \"samples\": [\n          53.38178253173828,\n          62.978336334228516,\n          34.172325134277344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High_XOM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.26551320129944,\n        \"min\": 25.560029259345043,\n        \"max\": 123.06591193790531,\n        \"num_unique_values\": 3942,\n        \"samples\": [\n          52.14369697640496,\n          52.04276157554843,\n          56.9474393237109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low_XOM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.852188091186957,\n        \"min\": 23.535549805605,\n        \"max\": 121.62427010512671,\n        \"num_unique_values\": 3943,\n        \"samples\": [\n          97.60004237904032,\n          30.42270080594235,\n          58.456832367150064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open_XOM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.054767952179226,\n        \"min\": 25.427146825868903,\n        \"max\": 122.00416271185078,\n        \"num_unique_values\": 3942,\n        \"samples\": [\n          51.81716627084806,\n          51.870591282678554,\n          56.60052900261151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume_XOM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9334747,\n        \"min\": 3851300,\n        \"max\": 118023500,\n        \"num_unique_values\": 3897,\n        \"samples\": [\n          20999200,\n          13363600,\n          23188500\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMA50\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.576492857373925,\n        \"min\": 28.383853492736815,\n        \"max\": 116.9209602355957,\n        \"num_unique_values\": 3895,\n        \"samples\": [\n          96.67561889648438,\n          53.598058471679686,\n          35.03529228210449\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMA200\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.864944953114254,\n        \"min\": 32.664792671203614,\n        \"max\": 112.69700580596924,\n        \"num_unique_values\": 3745,\n        \"samples\": [\n          100.99029285430908,\n          60.07380361557007,\n          44.34719738006592\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data_dict['XOM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXMM3Ga_oiDw"
      },
      "outputs": [],
      "source": [
        "for ticker, df in data_dict.items():\n",
        "  data_dict[ticker] = add_indicators(df, ticker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwKXB9JqoqKA"
      },
      "outputs": [],
      "source": [
        "# Clipping the first 200 rows to get a non null dataset in moving averages\n",
        "clip_rows = 200\n",
        "\n",
        "for ticker, df in data_dict.items():\n",
        "    # Drop the first 200 rows by slicing from row index 200 till end\n",
        "    clipped_df = df.iloc[clip_rows:].copy()\n",
        "\n",
        "    # Reset index if needed (optional, but often helpful)\n",
        "    clipped_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Update back to dictionary\n",
        "    data_dict[ticker] = clipped_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPRv27Cf29v1"
      },
      "outputs": [],
      "source": [
        "# Adding more features, that weren't present in the rule-based engine\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import classification_report, accuracy_score, balanced_accuracy_score, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def add_technical_features(df, ticker):\n",
        "    \"\"\"\n",
        "    REPLACES: Your original add_technical_features() function\n",
        "    LOCATION: Use this instead of your current technical features function\n",
        "    \"\"\"\n",
        "    close = df[f'Close_{ticker}']\n",
        "    high = df[f'High_{ticker}']\n",
        "    low = df[f'Low_{ticker}']\n",
        "    volume = df[f'Volume_{ticker}']\n",
        "\n",
        "    # MACD and Signal Line - These are fine as they use past data\n",
        "    exp12 = close.ewm(span=12, adjust=False).mean()\n",
        "    exp26 = close.ewm(span=26, adjust=False).mean()\n",
        "    df['MACD'] = exp12 - exp26\n",
        "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "\n",
        "    # Average True Range (ATR) - Fixed to use previous close properly\n",
        "    df['H-L'] = high - low\n",
        "    df['H-PC'] = abs(high - close.shift(1))\n",
        "    df['L-PC'] = abs(low - close.shift(1))\n",
        "    df['TR'] = df[['H-L', 'H-PC', 'L-PC']].max(axis=1)\n",
        "    df['ATR'] = df['TR'].rolling(window=14).mean()\n",
        "\n",
        "    # On-Balance Volume (OBV) - Vectorized and more efficient\n",
        "    df['Price_Change'] = np.where(close > close.shift(1), 1,\n",
        "                                 np.where(close < close.shift(1), -1, 0))\n",
        "    df['OBV'] = (df['Price_Change'] * volume).cumsum()\n",
        "\n",
        "    # Daily returns - Use previous day's return as feature\n",
        "    df['Daily_Return'] = close.pct_change()\n",
        "    df['Prev_Daily_Return'] = df['Daily_Return'].shift(1)\n",
        "\n",
        "    # Rolling volatility (20-day std) - This is correct\n",
        "    df['Rolling_Volatility'] = df['Daily_Return'].rolling(window=20).std()\n",
        "\n",
        "    # Momentum (10-day price diff) - This is correct\n",
        "    df['Momentum_10'] = close - close.shift(10)\n",
        "\n",
        "    # Add some additional useful features\n",
        "    # RSI (Relative Strength Index)\n",
        "    delta = close.diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # Bollinger Bands\n",
        "    df['BB_Middle'] = close.rolling(window=20).mean()\n",
        "    bb_std = close.rolling(window=20).std()\n",
        "    df['BB_Upper'] = df['BB_Middle'] + (bb_std * 2)\n",
        "    df['BB_Lower'] = df['BB_Middle'] - (bb_std * 2)\n",
        "    df['BB_Position'] = (close - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])\n",
        "\n",
        "    # Drop intermediate columns\n",
        "    df.drop(columns=['H-L', 'H-PC', 'L-PC', 'TR', 'Price_Change'], inplace=True)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKlhbdqX3Gd4"
      },
      "outputs": [],
      "source": [
        "for ticker, df in data_dict.items():\n",
        "    data_dict[ticker] = add_technical_features(df, ticker)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ticker in data_dict:\n",
        "  print(data_dict[ticker].isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXoWgzqwDC7n",
        "outputId": "4fe12402-ffb8-4fec-8060-477d61132821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Close_AAPL             0\n",
            "High_AAPL              0\n",
            "Low_AAPL               0\n",
            "Open_AAPL              0\n",
            "Volume_AAPL            0\n",
            "SMA50                  0\n",
            "SMA200                 0\n",
            "RSI                   13\n",
            "Bollinger_Upper        0\n",
            "Bollinger_Lower        0\n",
            "MACD                   0\n",
            "MACD_Signal            0\n",
            "ATR                   13\n",
            "OBV                    0\n",
            "Daily_Return           1\n",
            "Prev_Daily_Return      2\n",
            "Rolling_Volatility    20\n",
            "Momentum_10           10\n",
            "BB_Middle             19\n",
            "BB_Upper              19\n",
            "BB_Lower              19\n",
            "BB_Position           19\n",
            "dtype: int64\n",
            "Close_JPM              0\n",
            "High_JPM               0\n",
            "Low_JPM                0\n",
            "Open_JPM               0\n",
            "Volume_JPM             0\n",
            "SMA50                  0\n",
            "SMA200                 0\n",
            "RSI                   13\n",
            "Bollinger_Upper        0\n",
            "Bollinger_Lower        0\n",
            "MACD                   0\n",
            "MACD_Signal            0\n",
            "ATR                   13\n",
            "OBV                    0\n",
            "Daily_Return           1\n",
            "Prev_Daily_Return      2\n",
            "Rolling_Volatility    20\n",
            "Momentum_10           10\n",
            "BB_Middle             19\n",
            "BB_Upper              19\n",
            "BB_Lower              19\n",
            "BB_Position           19\n",
            "dtype: int64\n",
            "Close_XOM              0\n",
            "High_XOM               0\n",
            "Low_XOM                0\n",
            "Open_XOM               0\n",
            "Volume_XOM             0\n",
            "SMA50                  0\n",
            "SMA200                 0\n",
            "RSI                   13\n",
            "Bollinger_Upper        0\n",
            "Bollinger_Lower        0\n",
            "MACD                   0\n",
            "MACD_Signal            0\n",
            "ATR                   13\n",
            "OBV                    0\n",
            "Daily_Return           1\n",
            "Prev_Daily_Return      2\n",
            "Rolling_Volatility    20\n",
            "Momentum_10           10\n",
            "BB_Middle             19\n",
            "BB_Upper              19\n",
            "BB_Lower              19\n",
            "BB_Position           19\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5fBjKMM3SMy"
      },
      "outputs": [],
      "source": [
        "for ticker in data_dict:\n",
        "    data_dict[ticker].dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5H3YTZF3eKv"
      },
      "outputs": [],
      "source": [
        "def add_lag_features(data_dict, lag_days=[1, 2, 3, 5, 10]):\n",
        "    \"\"\"\n",
        "    Adds lag features for each column (per ticker) without requiring unified column names.\n",
        "\n",
        "    Parameters:\n",
        "        data_dict (dict): Dictionary of stock DataFrames (e.g., {'AAPL': df1, 'MSFT': df2, ...}).\n",
        "        lag_days (list): List of lag intervals to apply.\n",
        "\n",
        "    Returns:\n",
        "        dict: Updated dictionary with lag features added.\n",
        "    \"\"\"\n",
        "    for ticker, df in data_dict.items():\n",
        "        numeric_cols = df.select_dtypes(include='number').columns\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            for lag in lag_days:\n",
        "                df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
        "\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "    return data_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BUEm1Z0e43pr"
      },
      "outputs": [],
      "source": [
        "data_dict = add_lag_features(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OCMXfUu5YgM",
        "outputId": "d98d6f6c-20a2-4099-8991-33940fe12d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Close_AAPL\n",
            "High_AAPL\n",
            "Low_AAPL\n",
            "Open_AAPL\n",
            "Volume_AAPL\n",
            "SMA50\n",
            "SMA200\n",
            "RSI\n",
            "Bollinger_Upper\n",
            "Bollinger_Lower\n",
            "MACD\n",
            "MACD_Signal\n",
            "ATR\n",
            "OBV\n",
            "Daily_Return\n",
            "Prev_Daily_Return\n",
            "Rolling_Volatility\n",
            "Momentum_10\n",
            "BB_Middle\n",
            "BB_Upper\n",
            "BB_Lower\n",
            "BB_Position\n",
            "Close_AAPL_lag_1\n",
            "Close_AAPL_lag_2\n",
            "Close_AAPL_lag_3\n",
            "Close_AAPL_lag_5\n",
            "Close_AAPL_lag_10\n",
            "High_AAPL_lag_1\n",
            "High_AAPL_lag_2\n",
            "High_AAPL_lag_3\n",
            "High_AAPL_lag_5\n",
            "High_AAPL_lag_10\n",
            "Low_AAPL_lag_1\n",
            "Low_AAPL_lag_2\n",
            "Low_AAPL_lag_3\n",
            "Low_AAPL_lag_5\n",
            "Low_AAPL_lag_10\n",
            "Open_AAPL_lag_1\n",
            "Open_AAPL_lag_2\n",
            "Open_AAPL_lag_3\n",
            "Open_AAPL_lag_5\n",
            "Open_AAPL_lag_10\n",
            "Volume_AAPL_lag_1\n",
            "Volume_AAPL_lag_2\n",
            "Volume_AAPL_lag_3\n",
            "Volume_AAPL_lag_5\n",
            "Volume_AAPL_lag_10\n",
            "SMA50_lag_1\n",
            "SMA50_lag_2\n",
            "SMA50_lag_3\n",
            "SMA50_lag_5\n",
            "SMA50_lag_10\n",
            "SMA200_lag_1\n",
            "SMA200_lag_2\n",
            "SMA200_lag_3\n",
            "SMA200_lag_5\n",
            "SMA200_lag_10\n",
            "RSI_lag_1\n",
            "RSI_lag_2\n",
            "RSI_lag_3\n",
            "RSI_lag_5\n",
            "RSI_lag_10\n",
            "Bollinger_Upper_lag_1\n",
            "Bollinger_Upper_lag_2\n",
            "Bollinger_Upper_lag_3\n",
            "Bollinger_Upper_lag_5\n",
            "Bollinger_Upper_lag_10\n",
            "Bollinger_Lower_lag_1\n",
            "Bollinger_Lower_lag_2\n",
            "Bollinger_Lower_lag_3\n",
            "Bollinger_Lower_lag_5\n",
            "Bollinger_Lower_lag_10\n",
            "MACD_lag_1\n",
            "MACD_lag_2\n",
            "MACD_lag_3\n",
            "MACD_lag_5\n",
            "MACD_lag_10\n",
            "MACD_Signal_lag_1\n",
            "MACD_Signal_lag_2\n",
            "MACD_Signal_lag_3\n",
            "MACD_Signal_lag_5\n",
            "MACD_Signal_lag_10\n",
            "ATR_lag_1\n",
            "ATR_lag_2\n",
            "ATR_lag_3\n",
            "ATR_lag_5\n",
            "ATR_lag_10\n",
            "OBV_lag_1\n",
            "OBV_lag_2\n",
            "OBV_lag_3\n",
            "OBV_lag_5\n",
            "OBV_lag_10\n",
            "Daily_Return_lag_1\n",
            "Daily_Return_lag_2\n",
            "Daily_Return_lag_3\n",
            "Daily_Return_lag_5\n",
            "Daily_Return_lag_10\n",
            "Prev_Daily_Return_lag_1\n",
            "Prev_Daily_Return_lag_2\n",
            "Prev_Daily_Return_lag_3\n",
            "Prev_Daily_Return_lag_5\n",
            "Prev_Daily_Return_lag_10\n",
            "Rolling_Volatility_lag_1\n",
            "Rolling_Volatility_lag_2\n",
            "Rolling_Volatility_lag_3\n",
            "Rolling_Volatility_lag_5\n",
            "Rolling_Volatility_lag_10\n",
            "Momentum_10_lag_1\n",
            "Momentum_10_lag_2\n",
            "Momentum_10_lag_3\n",
            "Momentum_10_lag_5\n",
            "Momentum_10_lag_10\n",
            "BB_Middle_lag_1\n",
            "BB_Middle_lag_2\n",
            "BB_Middle_lag_3\n",
            "BB_Middle_lag_5\n",
            "BB_Middle_lag_10\n",
            "BB_Upper_lag_1\n",
            "BB_Upper_lag_2\n",
            "BB_Upper_lag_3\n",
            "BB_Upper_lag_5\n",
            "BB_Upper_lag_10\n",
            "BB_Lower_lag_1\n",
            "BB_Lower_lag_2\n",
            "BB_Lower_lag_3\n",
            "BB_Lower_lag_5\n",
            "BB_Lower_lag_10\n",
            "BB_Position_lag_1\n",
            "BB_Position_lag_2\n",
            "BB_Position_lag_3\n",
            "BB_Position_lag_5\n",
            "BB_Position_lag_10\n"
          ]
        }
      ],
      "source": [
        "for i in data_dict['AAPL']:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSDgL3I31yzU"
      },
      "outputs": [],
      "source": [
        "def generate_target_class(df, price_col='Close_AAPL', horizon=5, threshold=0.01):\n",
        "    \"\"\"\n",
        "    REPLACES: Your original generate_target_class() function\n",
        "    LOCATION: Use this instead of your current target generation\n",
        "    FIXES: Removes look-ahead bias\n",
        "    \"\"\"\n",
        "    # Calculate historical returns for training (no future data used)\n",
        "    df['historical_return'] = df[price_col].pct_change(periods=horizon).shift(-horizon)\n",
        "\n",
        "    # Create target classes based on historical data\n",
        "    df['target_class'] = 0\n",
        "    df.loc[df['historical_return'] > threshold, 'target_class'] = 1\n",
        "    df.loc[df['historical_return'] < -threshold, 'target_class'] = -1\n",
        "\n",
        "    # Remove the last 'horizon' rows as they don't have future data for training\n",
        "    df = df.iloc[:-horizon].copy()\n",
        "\n",
        "    # Drop the helper column\n",
        "    df.drop('historical_return', axis=1, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_balanced_targets(df, price_col, horizon=5):\n",
        "    \"\"\"\n",
        "    ADD THIS: New function to create better balanced targets\n",
        "    LOCATION: Add this as a new function alongside generate_target_class_fixed\n",
        "    PURPOSE: Creates more balanced target classes for better model performance\n",
        "    \"\"\"\n",
        "    # Calculate forward returns\n",
        "    future_returns = df[price_col].pct_change(periods=horizon).shift(-horizon)\n",
        "\n",
        "    # Method 1: Percentile-based targets (more balanced)\n",
        "    upper_percentile = future_returns.quantile(0.75)  # Top 25%\n",
        "    lower_percentile = future_returns.quantile(0.25)  # Bottom 25%\n",
        "\n",
        "    df['target_percentile'] = 0  # Middle 50%\n",
        "    df.loc[future_returns > upper_percentile, 'target_percentile'] = 1  # Top 25%\n",
        "    df.loc[future_returns < lower_percentile, 'target_percentile'] = -1  # Bottom 25%\n",
        "\n",
        "    # Method 2: Binary direction (simpler and often better)\n",
        "    df['target_direction'] = np.where(future_returns > 0, 1, 0)\n",
        "\n",
        "    # Remove last rows without future data\n",
        "    df = df.iloc[:-horizon].copy()\n",
        "\n",
        "    print(\"Target Distribution Comparison:\")\n",
        "    print(f\"Percentile-based: {df['target_percentile'].value_counts().sort_index()}\")\n",
        "    print(f\"Direction: {df['target_direction'].value_counts().sort_index()}\")\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuJOLB3p123r",
        "outputId": "d1e5ca9d-f184-4bc1-87df-bf668c9405fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boruta in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.11/dist-packages (from boruta) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.11/dist-packages (from boruta) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from boruta) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->boruta) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.17.1->boruta) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install boruta\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# ------------------ Helper Functions ------------------\n",
        "def create_time_series_splits(df, train_ratio=0.6, val_ratio=0.2):\n",
        "    \"\"\"\n",
        "    ADD THIS: New function for proper time series splitting\n",
        "    LOCATION: Add this as a completely new function\n",
        "    PURPOSE: Ensures chronological order in train/val/test splits\n",
        "    \"\"\"\n",
        "    n = len(df)\n",
        "    train_end = int(n * train_ratio)\n",
        "    val_end = int(n * (train_ratio + val_ratio))\n",
        "\n",
        "    train_df = df.iloc[:train_end].copy()\n",
        "    val_df = df.iloc[train_end:val_end].copy()\n",
        "    test_df = df.iloc[val_end:].copy()\n",
        "\n",
        "    print(f\"Train period: {train_end} samples\")\n",
        "    print(f\"Validation period: {len(val_df)} samples\")\n",
        "    print(f\"Test period: {len(test_df)} samples\")\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "def select_features_time_series(X_train, y_train, max_features=15):\n",
        "    \"\"\"\n",
        "    REPLACES: Your select_features_boruta_mi() function\n",
        "    LOCATION: Use this instead of your current feature selection\n",
        "    FIXES: Prevents data leakage in feature selection\n",
        "    \"\"\"\n",
        "    # Remove features with too many NaN values\n",
        "    na_threshold = 0.3  # Allow max 30% missing values\n",
        "    valid_features = X_train.columns[X_train.isnull().mean() < na_threshold]\n",
        "    X_train_clean = X_train[valid_features].fillna(method='ffill').fillna(0)\n",
        "\n",
        "    # Remove highly correlated features to prevent multicollinearity\n",
        "    corr_matrix = X_train_clean.corr().abs()\n",
        "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
        "    X_train_clean = X_train_clean.drop(columns=high_corr_features)\n",
        "\n",
        "    # Mutual information feature selection (only on training data)\n",
        "    mi_scores = mutual_info_classif(X_train_clean, y_train, discrete_features=False, random_state=42)\n",
        "    mi_series = pd.Series(mi_scores, index=X_train_clean.columns).sort_values(ascending=False)\n",
        "\n",
        "    # Select top features based on MI scores\n",
        "    selected_features = mi_series.head(max_features).index.tolist()\n",
        "\n",
        "    print(f\"Selected {len(selected_features)} features from {len(X_train.columns)} original features\")\n",
        "    print(f\"Top 10 features: {selected_features[:10]}\")\n",
        "\n",
        "    return selected_features, mi_series\n",
        "\n",
        "\n",
        "def walk_forward_validation(X, y, n_splits=5, min_train_size=252):\n",
        "    \"\"\"\n",
        "    Walk-forward validation for time series.\n",
        "    Each fold uses progressively more historical data.\n",
        "    \"\"\"\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits, test_size=None)\n",
        "\n",
        "    fold_results = []\n",
        "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
        "        # Ensure minimum training size\n",
        "        if len(train_idx) < min_train_size:\n",
        "            continue\n",
        "\n",
        "        X_train_fold = X.iloc[train_idx]\n",
        "        X_val_fold = X.iloc[val_idx]\n",
        "        y_train_fold = y.iloc[train_idx]\n",
        "        y_val_fold = y.iloc[val_idx]\n",
        "\n",
        "        fold_results.append({\n",
        "            'fold': fold,\n",
        "            'X_train': X_train_fold,\n",
        "            'X_val': X_val_fold,\n",
        "            'y_train': y_train_fold,\n",
        "            'y_val': y_val_fold,\n",
        "            'train_period': f\"{X_train_fold.index[0]} to {X_train_fold.index[-1]}\",\n",
        "            'val_period': f\"{X_val_fold.index[0]} to {X_val_fold.index[-1]}\"\n",
        "        })\n",
        "\n",
        "    return fold_results\n",
        "\n",
        "\n",
        "\n",
        "def select_features_time_series(X_train, y_train, X_val=None, y_val=None, max_features=20):\n",
        "    \"\"\"\n",
        "    Feature selection that prevents data leakage in time series.\n",
        "    Only uses training data for selection, then applies to validation/test.\n",
        "    \"\"\"\n",
        "    # Remove features with too many NaN values\n",
        "    na_threshold = 0.3  # Allow max 30% missing values\n",
        "    valid_features = X_train.columns[X_train.isnull().mean() < na_threshold]\n",
        "    X_train_clean = X_train[valid_features].fillna(method='ffill').fillna(0)\n",
        "\n",
        "    # Remove highly correlated features to prevent multicollinearity\n",
        "    corr_matrix = X_train_clean.corr().abs()\n",
        "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    high_corr_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
        "    X_train_clean = X_train_clean.drop(columns=high_corr_features)\n",
        "\n",
        "    # Mutual information feature selection (only on training data)\n",
        "    mi_scores = mutual_info_classif(X_train_clean, y_train, discrete_features=False, random_state=42)\n",
        "    mi_series = pd.Series(mi_scores, index=X_train_clean.columns).sort_values(ascending=False)\n",
        "\n",
        "    # Select top features based on MI scores\n",
        "    selected_features = mi_series.head(max_features).index.tolist()\n",
        "\n",
        "    # Validate feature importance with Random Forest (only on training data)\n",
        "    rf_selector = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        random_state=42,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        "    rf_selector.fit(X_train_clean[selected_features], y_train)\n",
        "\n",
        "    # Get feature importance\n",
        "    feature_importance = pd.Series(\n",
        "        rf_selector.feature_importances_,\n",
        "        index=selected_features\n",
        "    ).sort_values(ascending=False)\n",
        "\n",
        "    # Final feature selection\n",
        "    final_features = feature_importance.head(max_features).index.tolist()\n",
        "\n",
        "    print(f\"Selected {len(final_features)} features from {len(X_train.columns)} original features\")\n",
        "    print(f\"Top 10 features: {final_features[:10]}\")\n",
        "\n",
        "    return final_features, mi_series, feature_importance\n",
        "\n",
        "def prepare_features_for_prediction(X, selected_features):\n",
        "    \"\"\"\n",
        "    Prepare features for prediction, handling missing values appropriately.\n",
        "    \"\"\"\n",
        "    X_selected = X[selected_features].copy()\n",
        "\n",
        "    # Forward fill missing values (use last known value)\n",
        "    X_selected = X_selected.fillna(method='ffill')\n",
        "\n",
        "    # If still missing values at the beginning, fill with 0\n",
        "    X_selected = X_selected.fillna(0)\n",
        "\n",
        "    return X_selected\n",
        "\n",
        "def evaluate_model_properly(y_true, y_pred, method_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    ADD THIS: New function for proper model evaluation\n",
        "    LOCATION: Add this as a new function for better evaluation metrics\n",
        "    PURPOSE: Focuses on trading-relevant metrics instead of misleading accuracy\n",
        "    \"\"\"\n",
        "    print(f\"\\nðŸ“ˆ {method_name} Evaluation:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Standard metrics\n",
        "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "    regular_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"Regular Accuracy: {regular_acc:.4f}\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Per-class performance\n",
        "    report = classification_report(y_true, y_pred, output_dict=True)\n",
        "\n",
        "    if '-1' in report:  # Multi-class\n",
        "        print(f\"DOWN moves - Precision: {report['-1']['precision']:.3f}, Recall: {report['-1']['recall']:.3f}\")\n",
        "        print(f\"UP moves - Precision: {report['1']['precision']:.3f}, Recall: {report['1']['recall']:.3f}\")\n",
        "\n",
        "        # Trading-specific metrics\n",
        "        down_f1 = report['-1']['f1-score']\n",
        "        up_f1 = report['1']['f1-score']\n",
        "        directional_f1 = (down_f1 + up_f1) / 2\n",
        "        print(f\"Average Directional F1: {directional_f1:.3f}\")\n",
        "\n",
        "    else:  # Binary\n",
        "        print(f\"UP moves - Precision: {report['1']['precision']:.3f}, Recall: {report['1']['recall']:.3f}\")\n",
        "        print(f\"UP F1-Score: {report['1']['f1-score']:.3f}\")\n",
        "\n",
        "    return balanced_acc, regular_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_improved_workflow(data_dict, horizon=1, use_balanced_targets=True):\n",
        "    \"\"\"\n",
        "    REPLACES: Your entire workflow in the main execution\n",
        "    LOCATION: Use this as your main execution function\n",
        "    INTEGRATES: All the fixes and improvements in one place\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    for ticker, df in data_dict.items():\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Processing {ticker}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # Step 1: Feature Engineering (REPLACES your technical features call)\n",
        "        df_features = add_technical_features(df.copy(), ticker)\n",
        "        df_features = add_lag_features({ticker: df_features}, lag_days=[1, 2, 3, 5])[ticker]\n",
        "\n",
        "        # Step 2: Target Generation (CHOICE: balanced vs original)\n",
        "        if use_balanced_targets:\n",
        "            df_ml = create_balanced_targets(df_features.copy(),\n",
        "                                          price_col=f'Close_{ticker}',\n",
        "                                          horizon=horizon)\n",
        "            target_col = 'target_direction'  # Use binary direction\n",
        "        else:\n",
        "            df_ml = generate_target_class(df_features.copy(),\n",
        "                                              price_col=f'Close_{ticker}',\n",
        "                                              horizon=horizon,\n",
        "                                              threshold=0.01)\n",
        "            target_col = 'target_class'\n",
        "\n",
        "        # Step 3: Clean data\n",
        "        df_ml = df_ml.dropna()\n",
        "\n",
        "        if len(df_ml) < 500:\n",
        "            print(f\"Insufficient data for {ticker}: {len(df_ml)} rows\")\n",
        "            continue\n",
        "\n",
        "        # Step 4: Prepare features\n",
        "        feature_cols = [col for col in df_ml.columns\n",
        "                       if not col.startswith('target')\n",
        "                       and not col.startswith('future_return')\n",
        "                       and not col.startswith('historical_return')]\n",
        "\n",
        "        X = df_ml[feature_cols]\n",
        "        y = df_ml[target_col]\n",
        "\n",
        "        print(f\"Target distribution: {y.value_counts().sort_index().to_dict()}\")\n",
        "\n",
        "        # Step 5: Time Series Split (REPLACES any random splitting)\n",
        "        train_df, val_df, test_df = create_time_series_splits(df_ml,\n",
        "                                                            train_ratio=0.6,\n",
        "                                                            val_ratio=0.2)\n",
        "\n",
        "        X_train = train_df[feature_cols]\n",
        "        y_train = train_df[target_col]\n",
        "        X_val = val_df[feature_cols]\n",
        "        y_val = val_df[target_col]\n",
        "        X_test = test_df[feature_cols]\n",
        "        y_test = test_df[target_col]\n",
        "\n",
        "        # Step 6: Feature Selection (REPLACES your Boruta selection)\n",
        "        selected_features, mi_scores = select_features_time_series(X_train, y_train, max_features=15)\n",
        "\n",
        "        # Step 7: Prepare final datasets\n",
        "        X_train_final = X_train[selected_features].fillna(method='ffill').fillna(0)\n",
        "        X_val_final = X_val[selected_features].fillna(method='ffill').fillna(0)\n",
        "        X_test_final = X_test[selected_features].fillna(method='ffill').fillna(0)\n",
        "\n",
        "        # Step 8: Model Training\n",
        "        model = RandomForestClassifier(\n",
        "            n_estimators=200,\n",
        "            max_depth=8,\n",
        "            min_samples_split=20,\n",
        "            min_samples_leaf=10,\n",
        "            class_weight='balanced',\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        model.fit(X_train_final, y_train)\n",
        "\n",
        "        # Step 9: Validation and Testing\n",
        "        val_pred = model.predict(X_val_final)\n",
        "        test_pred = model.predict(X_test_final)\n",
        "\n",
        "        # Step 10: Proper Evaluation (REPLACES basic accuracy reporting)\n",
        "        val_balanced_acc, val_regular_acc = evaluate_model_properly(y_val, val_pred, \"Validation\")\n",
        "        test_balanced_acc, test_regular_acc = evaluate_model_properly(y_test, test_pred, \"Test\")\n",
        "\n",
        "        # Step 11: Store Results\n",
        "        results[ticker] = {\n",
        "            'model': model,\n",
        "            'selected_features': selected_features,\n",
        "            'val_balanced_acc': val_balanced_acc,\n",
        "            'val_regular_acc': val_regular_acc,\n",
        "            'test_balanced_acc': test_balanced_acc,\n",
        "            'test_regular_acc': test_regular_acc,\n",
        "            'target_distribution': y.value_counts().to_dict(),\n",
        "            'use_balanced_targets': use_balanced_targets\n",
        "        }\n",
        "\n",
        "        print(f\"\\nðŸŽ¯ SUMMARY FOR {ticker}:\")\n",
        "        print(f\"Validation - Regular Acc: {val_regular_acc:.4f}, Balanced Acc: {val_balanced_acc:.4f}\")\n",
        "        print(f\"Test - Regular Acc: {test_regular_acc:.4f}, Balanced Acc: {test_balanced_acc:.4f}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "N1ZW7YZHftFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = complete_improved_workflow(data_dict, horizon=1, use_balanced_targets=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "5AeINWT5fuH9",
        "outputId": "e57b17af-bad7-43c4-cb3a-e6236586735f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Processing AAPL\n",
            "==================================================\n",
            "Target Distribution Comparison:\n",
            "Percentile-based: target_percentile\n",
            "-1     921\n",
            " 0    1841\n",
            " 1     921\n",
            "Name: count, dtype: int64\n",
            "Direction: target_direction\n",
            "0    1732\n",
            "1    1951\n",
            "Name: count, dtype: int64\n",
            "Target distribution: {0: 1732, 1: 1951}\n",
            "Train period: 2209 samples\n",
            "Validation period: 737 samples\n",
            "Test period: 737 samples\n",
            "Selected 15 features from 572 original features\n",
            "Top 10 features: ['Daily_Return_lag_2', 'OBV', 'Daily_Return_lag_2_lag_5', 'Rolling_Volatility', 'BB_Position_lag_10_lag_5', 'RSI_lag_2', 'Daily_Return_lag_3_lag_5', 'Close_AAPL', 'Momentum_10_lag_2_lag_5', 'Prev_Daily_Return_lag_10']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-24-2941472757.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_improved_workflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_balanced_targets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-23-3543002507.py\u001b[0m in \u001b[0;36mcomplete_improved_workflow\u001b[0;34m(data_dict, horizon, use_balanced_targets)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Step 6: Feature Selection (REPLACES your Boruta selection)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mselected_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmi_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_features_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Step 7: Prepare final datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def complete_time_series_workflow(data_dict, horizon=5, threshold=0.01):\n",
        "    \"\"\"\n",
        "    Complete workflow for time series stock prediction with proper validation.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    for ticker, df in data_dict.items():\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Processing {ticker}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # 1. Feature Engineering (no look-ahead bias)\n",
        "        df_features = add_technical_features(df.copy(), ticker)\n",
        "        df_features = add_lag_features({ticker: df_features}, lag_days=[1, 2, 3, 5, 10])[ticker]\n",
        "\n",
        "        # 2. Target Generation (no look-ahead bias)\n",
        "        df_ml = generate_target_class(df_features.copy(),\n",
        "                                          price_col=f'Close_{ticker}',\n",
        "                                          horizon=horizon,\n",
        "                                          threshold=threshold)\n",
        "\n",
        "        # 3. Remove rows with NaN (important for time series)\n",
        "        df_ml = df_ml.dropna()\n",
        "\n",
        "        if len(df_ml) < 500:  # Need minimum data for meaningful results\n",
        "            print(f\"Insufficient data for {ticker}: {len(df_ml)} rows\")\n",
        "            continue\n",
        "\n",
        "        # 4. Prepare features and target\n",
        "        feature_cols = [col for col in df_ml.columns\n",
        "                       if not col.startswith('target')\n",
        "                       and not col.startswith('future_return')\n",
        "                       and not col.startswith('historical_return')]\n",
        "\n",
        "        X = df_ml[feature_cols]\n",
        "        y = df_ml['target_class']\n",
        "\n",
        "        # 5. Time Series Split (NO SHUFFLING!)\n",
        "        train_df, val_df, test_df = create_time_series_splits(df_ml,\n",
        "                                                            train_ratio=0.6,\n",
        "                                                            val_ratio=0.2)\n",
        "\n",
        "        X_train = train_df[feature_cols]\n",
        "        y_train = train_df['target_class']\n",
        "        X_val = val_df[feature_cols]\n",
        "        y_val = val_df['target_class']\n",
        "        X_test = test_df[feature_cols]\n",
        "        y_test = test_df['target_class']\n",
        "\n",
        "        # 6. Feature Selection (only on training data)\n",
        "        selected_features, mi_scores, feature_importance = select_features_time_series(\n",
        "            X_train, y_train, X_val, y_val, max_features=15\n",
        "        )\n",
        "\n",
        "        # 7. Prepare final datasets\n",
        "        X_train_final = prepare_features_for_prediction(X_train, selected_features)\n",
        "        X_val_final = prepare_features_for_prediction(X_val, selected_features)\n",
        "        X_test_final = prepare_features_for_prediction(X_test, selected_features)\n",
        "\n",
        "        # 8. Model Training\n",
        "        model = RandomForestClassifier(\n",
        "            n_estimators=200,\n",
        "            max_depth=8,\n",
        "            min_samples_split=20,\n",
        "            min_samples_leaf=10,\n",
        "            class_weight='balanced',\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        model.fit(X_train_final, y_train)\n",
        "\n",
        "        # 9. Validation\n",
        "        val_pred = model.predict(X_val_final)\n",
        "        val_accuracy = accuracy_score(y_val, val_pred)\n",
        "\n",
        "        # 10. Final Test (only if validation looks good)\n",
        "        test_pred = model.predict(X_test_final)\n",
        "        test_accuracy = accuracy_score(y_test, test_pred)\n",
        "\n",
        "        # 11. Walk-Forward Validation for robustness\n",
        "        wf_results = walk_forward_validation(X, y, n_splits=5)\n",
        "        wf_accuracies = []\n",
        "\n",
        "        for fold_data in wf_results:\n",
        "            fold_model = RandomForestClassifier(\n",
        "                n_estimators=100, max_depth=8,\n",
        "                class_weight='balanced', random_state=42\n",
        "            )\n",
        "\n",
        "            X_fold_train = prepare_features_for_prediction(fold_data['X_train'], selected_features)\n",
        "            X_fold_val = prepare_features_for_prediction(fold_data['X_val'], selected_features)\n",
        "\n",
        "            fold_model.fit(X_fold_train, fold_data['y_train'])\n",
        "            fold_pred = fold_model.predict(X_fold_val)\n",
        "            fold_accuracy = accuracy_score(fold_data['y_val'], fold_pred)\n",
        "            wf_accuracies.append(fold_accuracy)\n",
        "\n",
        "        # 12. Results Summary\n",
        "        results[ticker] = {\n",
        "            'model': model,\n",
        "            'selected_features': selected_features,\n",
        "            'val_accuracy': val_accuracy,\n",
        "            'test_accuracy': test_accuracy,\n",
        "            'wf_mean_accuracy': np.mean(wf_accuracies),\n",
        "            'wf_std_accuracy': np.std(wf_accuracies),\n",
        "            'feature_importance': feature_importance,\n",
        "            'data_shape': df_ml.shape,\n",
        "            'class_distribution': y.value_counts().to_dict()\n",
        "        }\n",
        "\n",
        "        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "        print(f\"Walk-Forward CV: {np.mean(wf_accuracies):.4f} Â± {np.std(wf_accuracies):.4f}\")\n",
        "        print(f\"Class Distribution: {y.value_counts().to_dict()}\")\n",
        "\n",
        "        # Classification report for detailed analysis\n",
        "        print(\"\\nTest Set Classification Report:\")\n",
        "        print(classification_report(y_test, test_pred))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage:\n",
        "results = complete_time_series_workflow(data_dict, horizon=1, threshold=0.02)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynPTzzLciD37",
        "outputId": "8ed2c23a-c5dd-4446-9d9a-241edb82a5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Processing AAPL\n",
            "==================================================\n",
            "Train period: 70 to 2272 (2203 samples)\n",
            "Validation period: 2273 to 3007 (735 samples)\n",
            "Test period: 3008 to 3742 (735 samples)\n",
            "Selected 15 features from 557 original features\n",
            "Top 10 features: ['BB_Position', 'Volume_AAPL', 'BB_Position_lag_1', 'Volume_AAPL_lag_1', 'MACD', 'Momentum_10', 'Rolling_Volatility', 'RSI_lag_5', 'BB_Position_lag_3', 'RSI']\n",
            "Validation Accuracy: 0.7265\n",
            "Test Accuracy: 0.7769\n",
            "Walk-Forward CV: 0.8049 Â± 0.0667\n",
            "Class Distribution: {0: 2993, 1: 354, -1: 326}\n",
            "\n",
            "Test Set Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.23      0.25      0.24        72\n",
            "           0       0.84      0.93      0.89       592\n",
            "           1       0.00      0.00      0.00        71\n",
            "\n",
            "    accuracy                           0.78       735\n",
            "   macro avg       0.36      0.39      0.37       735\n",
            "weighted avg       0.70      0.78      0.74       735\n",
            "\n",
            "\n",
            "==================================================\n",
            "Processing JPM\n",
            "==================================================\n",
            "Train period: 70 to 2272 (2203 samples)\n",
            "Validation period: 2273 to 3007 (735 samples)\n",
            "Test period: 3008 to 3742 (735 samples)\n",
            "Selected 15 features from 557 original features\n",
            "Top 10 features: ['Volume_JPM', 'Rolling_Volatility', 'Volume_JPM_lag_1', 'MACD', 'Close_JPM', 'Rolling_Volatility_lag_10', 'Volume_JPM_lag_3_lag_10', 'Volume_JPM_lag_2_lag_10', 'Daily_Return_lag_3_lag_10', 'Volume_JPM_lag_1_lag_3']\n",
            "Validation Accuracy: 0.7755\n",
            "Test Accuracy: 0.8422\n",
            "Walk-Forward CV: 0.8562 Â± 0.0680\n",
            "Class Distribution: {0: 3049, 1: 324, -1: 300}\n",
            "\n",
            "Test Set Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.09      0.04      0.05        52\n",
            "           0       0.87      0.97      0.92       631\n",
            "           1       0.40      0.08      0.13        52\n",
            "\n",
            "    accuracy                           0.84       735\n",
            "   macro avg       0.45      0.36      0.37       735\n",
            "weighted avg       0.78      0.84      0.80       735\n",
            "\n",
            "\n",
            "==================================================\n",
            "Processing XOM\n",
            "==================================================\n",
            "Train period: 70 to 2272 (2203 samples)\n",
            "Validation period: 2273 to 3007 (735 samples)\n",
            "Test period: 3008 to 3742 (735 samples)\n",
            "Selected 15 features from 557 original features\n",
            "Top 10 features: ['Volume_XOM', 'ATR', 'Volume_XOM_lag_1', 'RSI_lag_1', 'Rolling_Volatility', 'Volume_XOM_lag_5', 'Close_XOM', 'Rolling_Volatility_lag_10', 'OBV', 'Volume_XOM_lag_3']\n",
            "Validation Accuracy: 0.4626\n",
            "Test Accuracy: 0.6585\n",
            "Walk-Forward CV: 0.8141 Â± 0.1555\n",
            "Class Distribution: {0: 3125, 1: 283, -1: 265}\n",
            "\n",
            "Test Set Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.09      0.18      0.12        65\n",
            "           0       0.84      0.77      0.80       586\n",
            "           1       0.29      0.24      0.26        84\n",
            "\n",
            "    accuracy                           0.66       735\n",
            "   macro avg       0.41      0.40      0.40       735\n",
            "weighted avg       0.71      0.66      0.68       735\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_trading_performance(results_summary):\n",
        "    \"\"\"\n",
        "    Translate model metrics into trading reality.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TRADING REALITY CHECK\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Example for AAPL based on your results\n",
        "    print(\"\\nðŸ“Š AAPL Analysis:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Your model predictions vs reality\n",
        "    total_predictions = 735  # test set size\n",
        "    actual_up_moves = 71\n",
        "    actual_down_moves = 72\n",
        "\n",
        "    # What your model actually predicted (based on precision/recall)\n",
        "    predicted_up_correctly = int(0.00 * actual_up_moves)  # recall = 0.00\n",
        "    predicted_down_correctly = int(0.25 * actual_down_moves)  # recall = 0.25\n",
        "\n",
        "    print(f\"Total trading opportunities: {total_predictions} days\")\n",
        "    print(f\"Actual UP moves: {actual_up_moves} days\")\n",
        "    print(f\"Actual DOWN moves: {actual_down_moves} days\")\n",
        "    print(f\"Model correctly identified UP moves: {predicted_up_correctly} days\")\n",
        "    print(f\"Model correctly identified DOWN moves: {predicted_down_correctly} days\")\n",
        "\n",
        "    # Trading implications\n",
        "    print(f\"\\nðŸ’° Trading Implications:\")\n",
        "    print(f\"â€¢ Your model would miss {actual_up_moves - predicted_up_correctly} profitable UP opportunities\")\n",
        "    print(f\"â€¢ Your model would miss {actual_down_moves - predicted_down_correctly} profitable DOWN opportunities\")\n",
        "    print(f\"â€¢ Success rate for directional trades: ~{((predicted_up_correctly + predicted_down_correctly) / (actual_up_moves + actual_down_moves)) * 100:.1f}%\")\n",
        "\n",
        "    # What this means in dollars (hypothetical)\n",
        "    print(f\"\\nðŸ’¸ Hypothetical Trading Scenario:\")\n",
        "    print(f\"If each correct prediction = $100 profit:\")\n",
        "    print(f\"â€¢ Potential profits from UP moves: ${actual_up_moves * 100:,}\")\n",
        "    print(f\"â€¢ Your model would capture: ${predicted_up_correctly * 100:,}\")\n",
        "    print(f\"â€¢ Missed profits: ${(actual_up_moves - predicted_up_correctly) * 100:,}\")\n",
        "\n",
        "    return {\n",
        "        'total_opportunities': actual_up_moves + actual_down_moves,\n",
        "        'captured_opportunities': predicted_up_correctly + predicted_down_correctly,\n",
        "        'success_rate': ((predicted_up_correctly + predicted_down_correctly) / (actual_up_moves + actual_down_moves)) * 100\n",
        "    }\n",
        "\n",
        "# Run the analysis\n",
        "trading_analysis = analyze_trading_performance({})\n",
        "\n",
        "print(f\"\\nðŸŽ¯ BOTTOM LINE:\")\n",
        "print(f\"Your model is essentially a 'do nothing' strategy disguised as AI.\")\n",
        "print(f\"For actual trading, it would likely lose money due to:\")\n",
        "print(f\"1. Transaction costs on wrong predictions\")\n",
        "print(f\"2. Opportunity costs from missed moves\")\n",
        "print(f\"3. False signals leading to losses\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h81sy8xIoJH1",
        "outputId": "f89c77fd-b425-40c9-b368-cbcc2d1027e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "TRADING REALITY CHECK\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š AAPL Analysis:\n",
            "------------------------------\n",
            "Total trading opportunities: 735 days\n",
            "Actual UP moves: 71 days\n",
            "Actual DOWN moves: 72 days\n",
            "Model correctly identified UP moves: 0 days\n",
            "Model correctly identified DOWN moves: 18 days\n",
            "\n",
            "ðŸ’° Trading Implications:\n",
            "â€¢ Your model would miss 71 profitable UP opportunities\n",
            "â€¢ Your model would miss 54 profitable DOWN opportunities\n",
            "â€¢ Success rate for directional trades: ~12.6%\n",
            "\n",
            "ðŸ’¸ Hypothetical Trading Scenario:\n",
            "If each correct prediction = $100 profit:\n",
            "â€¢ Potential profits from UP moves: $7,100\n",
            "â€¢ Your model would capture: $0\n",
            "â€¢ Missed profits: $7,100\n",
            "\n",
            "ðŸŽ¯ BOTTOM LINE:\n",
            "Your model is essentially a 'do nothing' strategy disguised as AI.\n",
            "For actual trading, it would likely lose money due to:\n",
            "1. Transaction costs on wrong predictions\n",
            "2. Opportunity costs from missed moves\n",
            "3. False signals leading to losses\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}